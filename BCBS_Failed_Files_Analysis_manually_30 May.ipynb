{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d4cdf87-5f53-418c-bbfa-56584500a9d7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- file 1 : 2023-05_260_34P0_in-network-rates.json.gz  (Saved both tables)\n",
    "- file 2 : 2023-05_266_38B0_in-network-rates_2_of_3.json.gz (saved only Innetwork Table)\n",
    "- file 3 : 2023-05_266_38F0_in-network-rates_1_of_2.json.gz (saved only Innetwork Table)\n",
    "- file 4 : 2023-05_290_37B0_in-network-rates.json.gz (saved in both tables)\n",
    "- file 5 : 2023-05_290_37D0_in-network-rates.json.gz ( saved in both tables)\n",
    "- file 6 : 2023-05_302_42B0_in-network-rates_1_of_8.json.gz (saved only ProvRef Table)\n",
    "- file 7 : 2023-05_302_42B0_in-network-rates_2_of_8.json.gz (saved only ProvRef Table)\n",
    "- file 8 : 2023-05_302_42B0_in-network-rates_3_of_8.json.gz (saved only ProvRef Table)\n",
    "- file 9 : 2023-05_302_42B0_in-network-rates_4_of_8.json.gz (saved only ProvRef Table)\n",
    "- file 10 : 2023-05_302_42B0_in-network-rates_5_of_8.json.gz (running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1063cda-06b9-4145-b3bc-36988ea659c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "#Get the file name from the driver notebook\n",
    "# filename = dbutils.notebook.entry_point.getCurrentBindings()\n",
    "# fname =filename.get('filename')\n",
    "\n",
    "fname = \"dbfs:/mnt/floridablue/may2023/raw/ProviderReferences/2023-05_302_42B0_in-network-rates_5_of_8.json.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98d58302-1c45-4c10-ab26-0224da1ecf9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The File under process is :  2023-05_302_42B0_in-network-rates_5_of_8.json.gz\ncreated Provider ref\nwritten table  Provider ref\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# files=['dbfs:/mnt/march2023/ProviderReferences/smallFiles/2023-03_302_42F0_in-network-rates.json.gz']\n",
    "#Read the file from blob and get the schema\n",
    "# for file in files:\n",
    "#try:\n",
    "strInputFile = fname #'dbfs:/mnt/march2023/ProviderReferences/smallFiles/2023-03_230_30B0_in-network-rates.json.gz'\n",
    "try:\n",
    "    dfJSONML = spark.read.option('multiline',True).json(strInputFile)\n",
    "#         dfJSON.printSchema()\n",
    "#Get the file name to update into the table\n",
    "    strfname = strInputFile.split('/')\n",
    "    inputFileName = strfname[-1] \n",
    "    print('The File under process is : ',inputFileName)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "        #  spark.sql(f'update default.bcbs_florida_blue_may2023 set status=\"Failed at step 1\", process_date = CURRENT_DATE,Remarks=\"Unable to read the file with multiline option\" where fileName like \"%{inputFileName}%\"')\n",
    "\n",
    "\n",
    "df_Meta = dfJSONML.select(dfJSONML.reporting_entity_name,dfJSONML.reporting_entity_type,dfJSONML.version, dfJSONML.last_updated_on)\n",
    "#df_Meta.display()\n",
    "if 'provider_references' in dfJSONML.columns and 'npi' in dfJSONML.schema.simpleString():\n",
    "    try:\n",
    "        df_ProviderRef = dfJSONML.select('provider_references')\n",
    "        df_ProviderRef = df_ProviderRef.withColumn('provider_references',explode(col('provider_references')))\\\n",
    "                            .withColumn('provider_group_id',col('provider_references.provider_group_id'))\\\n",
    "                            .withColumn('provider_groups',explode(col('provider_references.provider_groups')))\\\n",
    "                            .withColumn('pg_npi',col('provider_groups.npi'))\\\n",
    "                            .withColumn('pg_tin_type',col('provider_groups.tin.type'))\\\n",
    "                            .withColumn('pg_tin_value',col('provider_groups.tin.value'))\\\n",
    "                            .withColumn('sourceFile',lit(input_file_name()))\\\n",
    "                            .withColumn('Created_Date',current_timestamp())\\\n",
    "                            .drop('provider_references','provider_groups')\n",
    "        print('created Provider ref')\n",
    "        df_ProviderRef.write.mode('append').saveAsTable('May_tblProviderReference_failed_files_retry')\n",
    "        print('written table  Provider ref')\n",
    "        # spark.sql(f'update default.bcbs_florida_blue_may2023 set status=\"Loaded Privder Ref\", process_date = CURRENT_DATE,Remarks=\"successfully updated provide ref table\" where fileName like \"%{inputFileName}%\"')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "            #  spark.sql(f'update default.bcbs_florida_blue_may2023 set status=\"Failed at step 2\", process_date = CURRENT_DATE,Remarks=\"Unable to load provider References\" where fileName like \"%{inputFileName}%\"')\n",
    "try:\n",
    "    dfJSON = spark.read.json(strInputFile)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "#     spark.sql(f'update default.bcbs_florida_blue_may2023 set status=\"Failed at step3\", process_date = CURRENT_DATE,Remarks=\"Unable to read the file without multiline option\" where fileName like \"%{inputFileName}%\"')\n",
    "# #         dfJSON.printSchema()\n",
    "schema = dfJSON.schema.simpleString()\n",
    "if 'provider_groups' in dfJSON.columns:\n",
    "    dfJSON = dfJSON.drop('provider_groups')\n",
    "if 'provider_references' in dfJSON.columns:\n",
    "    dfJSON = dfJSON.drop('provider_references')\n",
    "if 'provider_group_id' in dfJSON.columns:\n",
    "    dfJSON = dfJSON.drop('provider_group_id')    \n",
    "if 'bundled_codes' in dfJSON.columns:\n",
    "    dfJSON = dfJSON.drop('bundled_codes')\n",
    "\n",
    "if '_corrupt_record' in schema and len(dfJSON.columns)>1:\n",
    "    print('currupt record found')\n",
    "    \n",
    "    dfData = dfJSON.withColumn('exp_NegotiatedRates',explode(col('negotiated_rates')))\\\n",
    "                .drop('negotiated_rates','_corrupt_record')\\\n",
    "                .withColumn('provider_references', explode(col('exp_NegotiatedRates.provider_references')))\\\n",
    "                .withColumn('exp_negotiated_prices',explode(col('exp_NegotiatedRates.negotiated_prices')))\\\n",
    "                    .drop('exp_NegotiatedRates')\\\n",
    "                .withColumn('np_billing_class',col('exp_negotiated_prices.billing_class'))\\\n",
    "                .withColumn('np_expiration_date',col('exp_negotiated_prices.expiration_date'))\\\n",
    "                .withColumn('np_negotiated_rate',col('exp_negotiated_prices.negotiated_rate'))\\\n",
    "                .withColumn('np_negotiated_type',col('exp_negotiated_prices.negotiated_type'))\\\n",
    "                .withColumn('np_service_code',col('exp_negotiated_prices.service_code'))\\\n",
    "                .withColumn('sourceFile',lit(input_file_name()))\\\n",
    "                .withColumn('Created_Date',current_timestamp())\\\n",
    "                .drop('exp_negotiated_prices')\n",
    "\n",
    "    dfData = dfData.join(broadcast(df_Meta))\n",
    "    print('joined meta')\n",
    "    # dfData.printSchema()\n",
    "        \n",
    "else:\n",
    "    print(' no currupt record ')\n",
    "    dfJSON = dfJSONML\n",
    "    dfJSON = dfJSON.drop('provider_references')     \n",
    "    dfData = dfJSON.withColumn('in_network',explode(col('in_network')))\\\n",
    "                .drop('provider_references')\\\n",
    "                .withColumn('billing_code',col('in_network.billing_code'))\\\n",
    "                .withColumn('billing_code_type',col('in_network.billing_code_type'))\\\n",
    "                .withColumn('billing_code_type_version',col('in_network.billing_code_type_version'))\\\n",
    "                .withColumn('name',col('in_network.name'))\\\n",
    "                .withColumn('negotiation_arrangement',col('in_network.negotiation_arrangement'))\\\n",
    "                .withColumn('exp_NegotiatedRates',explode(col('in_network.negotiated_rates')))\\\n",
    "                .drop('negotiated_rates','in_network')\\\n",
    "                .withColumn('provider_references', explode(col('exp_NegotiatedRates.provider_references')))\\\n",
    "                .withColumn('exp_negotiated_prices',explode(col('exp_NegotiatedRates.negotiated_prices')))\\\n",
    "                    .drop('exp_NegotiatedRates')\\\n",
    "                .withColumn('np_billing_class',col('exp_negotiated_prices.billing_class'))\\\n",
    "                .withColumn('np_expiration_date',col('exp_negotiated_prices.expiration_date'))\\\n",
    "                .withColumn('np_negotiated_rate',col('exp_negotiated_prices.negotiated_rate'))\\\n",
    "                .withColumn('np_negotiated_type',col('exp_negotiated_prices.negotiated_type'))\\\n",
    "                .withColumn('np_service_code',col('exp_negotiated_prices.service_code'))\\\n",
    "                .withColumn('sourceFile',lit(input_file_name()))\\\n",
    "                .withColumn('Created_Date',current_timestamp())\\\n",
    "                .drop('exp_negotiated_prices')\n",
    "    # dfData.printSchema()\n",
    "dfData = dfData.withColumn('np_service_code',explode(col('np_service_code')))\n",
    "# #Saving the innetwork details into table\n",
    "dfData = dfData.where(dfData.np_service_code.isin('-1','02','11','20','21','22','23','31','32','34','51','61'))\n",
    "dfData= dfData.withColumn('np_negotiated_rate',dfData.np_negotiated_rate.cast('double'))\n",
    "try:\n",
    "    dfData.write.mode('append').option('mergeSchema',True).saveAsTable('may_tblProviderReferenceInNetwork_Mano')\n",
    "    print('written to  Provider references innetwork')\n",
    "#     spark.sql(f'update default.bcbs_florida_blue_may2023 set status=\"Loaded both Provider references and innetwork\", process_date = CURRENT_DATE,Remarks=\"Both atables loaded\" where fileName like \"%{inputFileName}%\"')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "#     spark.sql(f'update default.bcbs_florida_blue_may2023 set status=\"Failed at step 4\", process_date = CURRENT_DATE,Remarks=\"Unable to load into provider references innetwork\" where fileName like \"%{inputFileName}%\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a976d4c3-cb5d-4506-8831-4cbc065c41d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- in_network: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- billing_code: string (nullable = true)\n |    |    |-- billing_code_type: string (nullable = true)\n |    |    |-- billing_code_type_version: string (nullable = true)\n |    |    |-- bundled_codes: array (nullable = true)\n |    |    |    |-- element: struct (containsNull = true)\n |    |    |    |    |-- billing_code: string (nullable = true)\n |    |    |    |    |-- billing_code_type: string (nullable = true)\n |    |    |    |    |-- billing_code_type_version: string (nullable = true)\n |    |    |    |    |-- description: string (nullable = true)\n |    |    |-- description: string (nullable = true)\n |    |    |-- name: string (nullable = true)\n |    |    |-- negotiated_rates: array (nullable = true)\n |    |    |    |-- element: struct (containsNull = true)\n |    |    |    |    |-- negotiated_prices: array (nullable = true)\n |    |    |    |    |    |-- element: struct (containsNull = true)\n |    |    |    |    |    |    |-- billing_class: string (nullable = true)\n |    |    |    |    |    |    |-- billing_code_modifier: array (nullable = true)\n |    |    |    |    |    |    |    |-- element: string (containsNull = true)\n |    |    |    |    |    |    |-- expiration_date: string (nullable = true)\n |    |    |    |    |    |    |-- negotiated_rate: double (nullable = true)\n |    |    |    |    |    |    |-- negotiated_type: string (nullable = true)\n |    |    |    |    |    |    |-- service_code: array (nullable = true)\n |    |    |    |    |    |    |    |-- element: string (containsNull = true)\n |    |    |    |    |-- provider_references: array (nullable = true)\n |    |    |    |    |    |-- element: double (containsNull = true)\n |    |    |-- negotiation_arrangement: string (nullable = true)\n |-- last_updated_on: string (nullable = true)\n |-- provider_references: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- provider_group_id: double (nullable = true)\n |    |    |-- provider_groups: array (nullable = true)\n |    |    |    |-- element: struct (containsNull = true)\n |    |    |    |    |-- npi: array (nullable = true)\n |    |    |    |    |    |-- element: long (containsNull = true)\n |    |    |    |    |-- tin: struct (nullable = true)\n |    |    |    |    |    |-- type: string (nullable = true)\n |    |    |    |    |    |-- value: string (nullable = true)\n |-- reporting_entity_name: string (nullable = true)\n |-- reporting_entity_type: string (nullable = true)\n |-- version: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "dfJSONML.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fafb0c6b-93d8-44c4-ad2d-6277cf71c826",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %sql\n",
    "# select DISTINCT (sourceFile) AS sourceFile from tblProviderReferenceInNetworkmay -- where sourcefile in ('dbfs:/mnt/march2023/ProviderReferences/smallFiles/2023-03_302_42F0_in-network-rates.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db572338-92ec-46b7-aad1-f9c57c10326f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dbutils.notebook.exit(\"File Execution is successfully completed\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1903612097786680,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "BCBS_Failed_Files_Analysis_manually_30 May",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
